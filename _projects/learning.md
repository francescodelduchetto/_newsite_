---
layout: page
title: Learning from the human feedback
description: This line of work explores ways robots deployed "in the wild" can learn leverage the human presence for learning to get better over time, improving quality of human-robot interaction and the robot's autonomy.
img: assets/img/lindblur-short.jpg
importance: 1
category: research
related_publications: del2019lindsey, del2020automatic, brown2020abstract, del2022learning, del2018not
---
## Summary

When we take our robots outside the labs, due to the unconstrained nature of real-world deployments where the environment is unknown, always changing and contains people (whose behaviour is typically unpredictable), designing robots that can function autonomously becomes a very challenging task. However, the presence of humans in these enviornments provide a great opportunity for robots to learn how to improve their abilities —for example, on how to <a href="#del2022learning">become more engaging to users during  guided tours in a museum (Del Duchetto 2022)</a>— and how to correct errors —such as, <a href="#del2018not">improving navigation from human demonstrated recovery trajectories (Del Duchetto 2018)</a>. I am interested in creating interfaces of communication between robots and their users to enable natural interactions and robot learning in situated interactions.

## Videos

<div class="row">
    <div class="col-6">
        <iframe width="560" height="315" src="https://www.youtube-nocookie.com/embed/uBhuVh7Az4Y?si=rXr6pOujyaEbqp4G" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>
    </div>
    <div class="col-6">
        <iframe width="560" height="315" src="https://www.youtube-nocookie.com/embed/gt84MNj_NdQ?si=M3P6UisUQREBGPki" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>
    </div>
</div>
<div class="row">
    <div class="col-6">
        <iframe width="560" height="315" src="https://www.youtube-nocookie.com/embed/05JMypZElnU?si=eOKIy_GxScrJ9umi" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share"  allowfullscreen></iframe>
    </div>
</div>

## Projects

- **Lindsey: the Tour Guide Robot**, Funded by *Lincolnshire County Council*, Partners: University of Lincoln (PI: Prof Marc Hanheide). Link: <a href="https://lcas.lincoln.ac.uk/wp/projects/lindsey-a-robot-tour-guide">https://lcas.lincoln.ac.uk/wp/projects/lindsey-a-robot-tour-guide/</a>
- **Trustworthy Accessible Robots for Inclusive Cultural experienceS (TARICS)**, Funded by *UKRI TAS Hub*, Partners: University of Lincoln (PI: Maria Galvez Trigo), University of Nottingham, Lincolnshire County Council, NICER Group - Nottingham International Consortium for Educational Research. Link: <a href="https://tas.ac.uk/research-projects-2022-23/tarics/">https://tas.ac.uk/research-projects-2022-23/tarics/</a>
